% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/learnDTR.cont.R
\name{learnDTR.cont}
\alias{learnDTR.cont}
\title{Learning DTR from Sequential Interventions (Continuous Treatment)}
\usage{
learnDTR.cont(
  X,
  A,
  Y,
  weights = rep(1, length(X)),
  baseLearner = c("RF", "BART", "XGBoost", "GAM"),
  metaLearners = c("S"),
  include.X = 0,
  include.A = 0,
  include.Y = 0,
  parallel = FALSE,
  parallel.package = "doMC",
  A.box.cnstr = NULL,
  A.cnstr.func = NULL,
  x.select = NULL,
  n.grid = 100,
  verbose = TRUE,
  verbose.parallel = FALSE,
  ...
)
}
\arguments{
\item{X}{A list of information available at each stage in order, that is, \code{X[[1]]} represents the baseline information,
and \code{X[[t]]} is the information observed before \eqn{t^{th}} intervention.
The dimensionality of each element \code{X[[i]]} can be different from each other.
Notably, it can includes previous stages' action information \code{A} and outcome/reward information
\code{Y}. User can flexibly manipulate which covariates to use in training.
However, if argument \code{all.inclusive} is \code{TRUE}, all previous stages' \code{X}, \code{A},
and \code{Y} will be used in training. So, in that case, \code{X} should not involve action and reward
information.}

\item{A}{A list of actions taken during the sequential studies. The order should match with that of \code{X}}

\item{Y}{A list of outcomes observed in the sequential studies. The order should match with that of \code{X}.
\code{Y[[t]]} is suppose to be driven by the \code{X[[t]]} and action \code{A[[t]]}.}

\item{weights}{Weights on each stage of rewards. Default is all 1.}

\item{baseLearner}{Choose one baselearner for meta-learn er algorithms. So far, it supports \code{BART} by
package \code{dbarts}, \code{RF} (random forests) by \code{ranger}, \code{XGBoost} by
package \code{xgboost}, and \code{GAM} (generalized additive model)
through package \code{glmnet}, which can provide variable selection/sparsity by
various type of regularization. So more in details.}

\item{metaLearners}{\code{c("S")}. For continuous treatment assignment, only S-learner type is available.}

\item{include.X}{0 for no past X included in analysis; 1 for all past X included}

\item{include.A}{0 for no past treatment assignment included in analysis; 1 for only last A included; 2 for all past
A included}

\item{include.Y}{0 for no past reward/outcome Y included in analysis; 1 for only last Y included; 2 for all past
Y included}

\item{parallel}{A boolean, for whether parallel computing is adopted to speed up the "prediction" steps.
It might induce certain connection issue with \code{glmnet}. But parallel is not really
necessary. It does not impact training speed. Also, if a numeric value, it implies the
number of cores to use. Otherwise, directly use the number from \code{detectCores()}.}

\item{parallel.package}{One of c("doMC", "snow", "doParallel"), the parallel package to use. Only \code{BART}
seems matches better with \code{snow}, while the others, like \code{XGBoost},
\code{RF}, and \code{GAM} prefers \code{doMC}. So please check which parallel structure
fits the best on the chosen algorithm before running heavy duty.}

\item{A.box.cnstr}{Box constraint for A. Default is \code{NULL}, which means no constraint on A
and the feasible set of A will be implied from observed action values}

\item{A.cnstr.func}{For other type of constraint applied to A, user can input a function here.
The basic syntax is \code{function(A, X){...}}, with two arguments: A stands
for action and X are covariates at that stage. For which covariates to select,
use the argument \code{x.select}. The function should return a boolean,
i.e., \code{TRUE} or \code{FALSE}. For example, if constraint is \eqn{3A-log(A)<5},
then function is \code{function(A, X){3A-log(A)<5}}.}

\item{x.select}{Covariate names or id (numeric). Default is \code{NULL} means either all variables are
selected (if X is used in function \code{A.cnstr.func}) or X is not related to A's feasible set}

\item{n.grid}{Number of grid used to search for the best treatment/action. Large values slow down the algorithm.}

\item{verbose}{Console print allowed?}

\item{verbose.parallel}{Verbose specifically for parallel computing. May slow down the computation}

\item{...}{Additional arguments that can be passed to \code{dbarts::bart}, \code{ranger::ranger},
\code{params} of \code{xbgoost::xgb.cv}, or \code{glmnet::cv.glmnet}}
}
\value{
It includes learning results, basically, the trained functions that can be used for predictions. Since
sequential recommendations might require intermediate observations, \link{learnDTR.cont} will not automatically
provide prediction. But by another function \link{recommendDTR.cont},
predictions can flexibly been made stage by stage.
}
\description{
This function supports to learn the optimal sequential decision rules from either randomized studies
or observational ones. Multiple treatment options are supported.
}
\details{
This function supports to find the optimal dynamic treatment regime (DTR) for either randomized experiments
or observational studies. Also, thanks to meta-learner structure, S-, T-, and deC-learner can naturally
support multiple action options at any stage. \cr
\cr
For \code{GAM}, the algorithm will not automatically project the covariates \code{X} or outcomes/rewards
\code{Y} onto any bases-spanned spaces. User shall transform the covariates and/or  outcomes/rewards
manually and then input the desired design matrix through inputs \code{X} and/or \code{Y}.\cr
\cr
It is strongly suggested to adopt BART over random forests as baselearner if sample size is small.
}
\examples{
## Though ThreeStg_Dat does not have continuous treatment, still we can use it as an example
DTRs = learnDTR.cont(X = ThreeStg_Dat$X,
                     A = ThreeStg_Dat$A,
                     Y = ThreeStg_Dat$Y,
                     weights = rep(1, 3),
                     baseLearner  = c("BART"),
                     metaLearners = c("S"),
                     include.X = 1,
                     include.A = 2,
                     include.Y = 0)
}
\references{
Künzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu.
"Metalearners for estimating heterogeneous treatment effects using machine learning."
\emph{Proceedings of the national academy of sciences} 116, no. 10 (2019): 4156-4165.
\cr\cr
Zhou, Junyi, Ying Zhang, and Wanzhu Tu. "A reference-free R-learner for treatment recommendation."
\emph{Statistical Methods in Medical Research} (2022)
}
\seealso{
\code{\link{recommendDTR.cont}}
}
\author{
Junyi Zhou \email{junyzhou@iu.edu}
}
