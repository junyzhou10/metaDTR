% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/learnDTR.R
\name{learnDTR}
\alias{learnDTR}
\title{Learning DTR from Sequential Interventions}
\usage{
learnDTR(
  X,
  A,
  Y,
  weights = rep(1, length(X)),
  baseLearner = c("BART", "GAM"),
  metaLearners = c("S", "T", "deC"),
  include.X = 0,
  include.A = 0,
  include.Y = 0,
  verbose = TRUE,
  ...
)
}
\arguments{
\item{X}{A list of information available at each stage in order, that is, \code{X[[1]]} represents the baseline information,
and \code{X[[t]]} is the information observed before \eqn{t^{th}} intervention.
The dimensionality of each element \code{X[[i]]} can be different from each other.
Notably, it can includes previous stages' action information \code{A} and outcome/reward information
\code{Y}. User can flexibly manipulate which covariates to use in training.
However, if argument \code{all.inclusive} is \code{TRUE}, all previous stages' \code{X}, \code{A},
and \code{Y} will be used in training. So, in that case, \code{X} should not involve action and reward
information.}

\item{A}{A list of actions taken during the sequential studies. The order should match with that of \code{X}}

\item{Y}{A list of outcomes observed in the sequential studies. The order should match with that of \code{X}.
\code{Y[[t]]} is suppose to be driven by the \code{X[[t]]} and action \code{A[[t]]}.}

\item{weights}{Weights on each stage of rewards. Default is all 1.}

\item{baseLearner}{Choose one baselearner for meta-learn er algorithms. So far supports \code{BART} and
\code{GAM} through package \code{glmnet}, which can provide variable selection by
regularization.}

\item{metaLearners}{\code{c("S", "T", "deC")}. Meta-learner algorithms to learn the optimal DTR. To support more than two actions
at each stage, S-, A-, and deC-learner are available. But deC-learner only works when
\code{baseLearner = "GAM"} so far.}

\item{include.X}{0 for no past X included in analysis; 1 for all past X included}

\item{include.A}{0 for no past treatment assignment included in analysis; 1 for only last A included; 2 for all past
A included}

\item{include.Y}{0 for no past reward/outcome Y included in analysis; 1 for only last Y included; 2 for all past
Y included}

\item{verbose}{Console print allowed?}

\item{...}{Additional arguments that can be passed to \code{dbarts::bart} or \code{glmnet::cv.glmnet}
If \code{TRUE}, covariates adopted in training at stage \code{T} includes
\code{X[[t]], t<=T}, \code{A[[t]], t<T}, and \code{Y[[t]], t<T}. In other words,
\code{X} actually should only store additional covariates at each stage. Note that if
there are subjects dropping out during the study, it will cause error.}
}
\value{
It includes learning results, basically, the trained functions that can be used for predictions. Since
sequential recommendations might require intermediate observations, \code{\link[=learnDTR]{learnDTR()}} will not automatically
provide prediction. But by another function \link{recommendDTR},
predictions can flexibly been made stage by stage.
}
\description{
This function supports to learn the optimal sequential decision rules from either randomized studies
or observational ones. Multiple treatment options are supported.
}
\details{
This function supports to find the optimal dynamic treatment regime (DTR) for either randomized experiments
or observational studies. Also, thanks to meta-learner structure, S-, T-, and deC-learner can naturally
support multiple action options at any stage. \cr
\cr
For \code{GAM}, the algorithm will not automatically project the covariates \code{X} or outcomes/rewards
\code{Y} onto any bases-spanned spaces. User shall transform the covariates and/or  outcomes/rewards
manually and then input the desired design matrix through inputs \code{X} and/or \code{Y}.
}
\examples{
## this is the sample adopted in:
## https://jzhou.org/posts/optdtr/#case-1-random-assignment-with-two-treatment-options
DTRs = learnDTR(X = TwoStg_Dat$X,
                A = TwoStg_Dat$A,
                Y = TwoStg_Dat$Y,
                weights = rep(1, 3),
                baseLearner  = c("BART"),
                metaLearners = c("S", "T"),
                include.X = 1,
                include.A = 2,
                include.Y = 0)
}
\references{
Künzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu.
"Metalearners for estimating heterogeneous treatment effects using machine learning."
\emph{Proceedings of the national academy of sciences} 116, no. 10 (2019): 4156-4165.
\cr\cr
Zhou, Junyi, Ying Zhang, and Wanzhu Tu. "A reference-free R-learner for treatment recommendation."
\emph{Statistical Methods in Medical Research} (2022)
}
\seealso{
\code{\link{recommendDTR}}
}
\author{
Junyi Zhou \email{junyzhou@iu.edu}
}
